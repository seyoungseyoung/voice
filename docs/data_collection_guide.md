# 데이터 수집 가이드

## 1. AI Hub 데이터 수집

### 필요 데이터셋
- **보이스피싱 음성 데이터** (약 10,000건 이상)
- **민원 질의응답 데이터**

### 수집 절차
1. [AI Hub](https://aihub.or.kr) 접속 및 회원가입/로그인
2. 검색창에서 다음 키워드 검색:
   - "보이스피싱"
   - "음성 인식"
   - "대화 음성"
3. 데이터셋 신청 및 승인 대기 (통상 1-2일 소요)
4. 승인 후 데이터 다운로드
5. 다운로드한 파일을 `data/raw/aihub/` 디렉토리에 저장

### 데이터 포맷
- 음성 파일: WAV, MP3, FLAC
- 메타데이터: JSON 또는 CSV
- 라벨링 정보: 대화 스크립트, 화자 정보

## 2. 금융감독원 데이터 수집

### 그놈 목소리 체험관
- URL: https://voice.fss.or.kr
- 실제 보이스피싱 사례 녹음 파일 제공

### 수집 방법
1. 웹사이트 접속
2. 각 사례별 음성 파일 재생
3. 브라우저 개발자 도구를 통한 오디오 URL 확인
4. 다운로드 후 `data/raw/fss/` 디렉토리에 저장

**주의사항**: 저작권 및 이용 약관 확인 필수

## 3. 추가 데이터 소스

### 공공 데이터 포털
- [공공데이터포털](https://www.data.go.kr)
- 경찰청, 금융위원회 보이스피싱 관련 데이터

### YouTube 음성 데이터
- 보이스피싱 예방 교육 영상
- 실제 사례 재연 콘텐츠
- 주의: 저작권 문제 확인 필요

## 4. 데이터 검증

수집된 데이터는 다음을 확인:
- [ ] 음질 (최소 8kHz 샘플링 레이트)
- [ ] 화자 분리 가능 여부
- [ ] 스크립트/라벨 존재 여부
- [ ] 파일 손상 없음

## 5. 데이터 수집 스크립트 실행

```bash
# 가상환경 활성화
source venv/bin/activate  # Windows: venv\Scripts\activate

# 데이터 수집 스크립트 실행
python scripts/collect_data.py
```

## 6. 예상 데이터 규모

| 출처 | 예상 파일 수 | 예상 용량 |
|------|-------------|----------|
| AI Hub | 10,000+ | 20-50 GB |
| 금융감독원 | 100+ | 1-5 GB |
| 기타 공공데이터 | 1,000+ | 5-10 GB |
| **합계** | **11,000+** | **26-65 GB** |

## 7. 다음 단계

데이터 수집 완료 후:
1. `src/data/preprocessor.py` 를 통한 전처리
2. 노이즈 제거 및 정규화
3. Speaker Diarization
4. 라벨링 및 태깅
