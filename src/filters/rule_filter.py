"""
Rule-based Filter for reducing False Positives
ë…¼ë¦¬ì  í•„í„°ë¡œ ì •ìƒ ì„œë¹„ìŠ¤(ì›ê²©ì§€ì›, ì±„ìš©ê²€ì‚¬ ë“±)ë¥¼ ë³´í˜¸
"""
import logging
from typing import Dict, Optional

logger = logging.getLogger(__name__)

# 2ì°¨ LLM ê²€ì¦ì„ ìœ„í•´ Gemini Client import
try:
    from src.llm.llm_clients.gemini_client import GeminiClient
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    logger.warning("GeminiClient not available - 2nd stage verification disabled")


class RuleBasedFilter:
    """
    LLM íŒì • í›„ 2ì°¨ ê²€ì¦ í•„í„°
    ëª©ì : False Positive ê°ì†Œ (ì •ìƒ ì›ê²©ì§€ì› ì„œë¹„ìŠ¤ ë³´í˜¸)
    """

    # ë²”ì£„ ì˜ë„ í‚¤ì›Œë“œ (í”¼ì‹± ì‹ í˜¸)
    CRIME_KEYWORDS = [
        # ê¸ˆìœµ ê´€ë ¨
        "ì†¡ê¸ˆ", "ê³„ì¢Œ", "ì…ê¸ˆ", "ì¶œê¸ˆ", "ì´ì²´", "í™˜ë¶ˆ", "í™˜ê¸‰",
        "ëŒ€í¬í†µì¥", "ê¸ˆì „", "ëˆ", "í˜„ê¸ˆ", "ì¹´ë“œë²ˆí˜¸", "ë¹„ë°€ë²ˆí˜¸",
        "ë³´ì•ˆì½”ë“œ", "OTP", "ê³µì¸ì¸ì¦ì„œ", "ê¸ˆìœµê±°ë˜",

        # ìˆ˜ì‚¬ê¸°ê´€ ì‚¬ì¹­
        "ê²€ì°°", "ê²½ì°°", "ê²€ì‚¬", "í˜•ì‚¬", "ìˆ˜ì‚¬", "ë²”ì£„", "í”¼ì˜ì",
        "ì˜ì¥", "ì²´í¬", "êµ¬ì†", "ìˆ˜ë°°", "ì¡°ì‚¬", "ì¶œì„",

        # ê¸ˆìœµê¸°ê´€ ì‚¬ì¹­
        "ê¸ˆê°ì›", "ê¸ˆìœµê°ë…ì›", "ê¸ˆìœµìœ„ì›íšŒ", "í•œêµ­ì€í–‰",
        "ì˜ˆê¸ˆë³´í—˜ê³µì‚¬", "ì‹ ìš©ì •ë³´ì›",

        # ë””ì§€í„¸ ê°ê¸ˆ íŒ¨í„´
        "ëª¨í…”", "ìˆ™ë°•", "í˜¸í…”", "ë…ë¦½ëœ ê³µê°„", "ì¡°ìš©í•œ ê³³",
        "ì´ë™", "ì¥ì†Œ", "ìœ„ì¹˜", "í° ë„ì§€",

        # ì•…ì„± ì•±/URL
        "APK", "ì„¤ì¹˜", "ë‹¤ìš´ë¡œë“œ", "ë§í¬", "URL", "ì ‘ì†",
        ".com", ".net", ".info", "bit.ly"
    ]

    # ì •ìƒ ì„œë¹„ìŠ¤ í‚¤ì›Œë“œ (í•©ë²• ì‹ í˜¸)
    LEGIT_KEYWORDS = [
        # ê³µì‹ ì„œë¹„ìŠ¤
        "ì„œë¹„ìŠ¤ì„¼í„°", "ê³ ê°ì„¼í„°", "ìƒë‹´ì„¼í„°", "ì½œì„¼í„°",
        "AS", "A/S", "ê¸°ì‚¬ë‹˜", "ìƒë‹´ì‚¬", "ë‹´ë‹¹ì",

        # ì˜ˆì•½/ì¼ì •
        "ì˜ˆì•½", "ì˜ˆì •", "ì•ˆë‚´", "ì¼ì •", "ì‹œê°„",

        # ê³µì‹ ì±„ë„ (ëª…í™•íˆ "ê³µì‹"ì´ë¼ëŠ” ë‹¨ì–´ê°€ ë¶™ì€ ê²½ìš°ë§Œ)
        "ê³µì‹ í™ˆí˜ì´ì§€", "ê³µì‹ ì‚¬ì´íŠ¸", "ê³µì‹ ì•±", "ê³µì‹ ì–´í”Œ",
        "ë§ˆì´í˜ì´ì§€", "ì¹´ì¹´ì˜¤í†¡", "ì¤Œ", "Zoom", "í™”ìƒ",

        # ì›ê²© ì§€ì›
        "ì ‘ì†ë²ˆí˜¸", "ì›ê²© ìƒë‹´", "ê¸°ë³¸ ì„¤ì •", "ê¸°ë³¸ ê¸°ëŠ¥",
        "ì„¤ì • ë©”ë‰´", "í™”ë©´ ê³µìœ ",

        # ì±„ìš©/ë©´ì ‘
        "ì±„ìš©", "ë©´ì ‘", "ì¸ì‚¬íŒ€", "í•©ê²©", "ì§€ì›", "ì‘ì‹œ",
        "ì‹œí—˜", "ê²€ì‚¬", "ì—­ëŸ‰", "ì„œë¥˜",

        # ì˜ë£Œ
        "ì§„ë£Œ", "ìƒë‹´", "ë³‘ì›", "ì˜ì‚¬", "í™˜ì", "í”„ë¼ì´ë²„ì‹œ",

        # ë¶€ë™ì‚°/ë²•ë¥  (ì •ìƒ ê±°ë˜)
        "ë¶€ë™ì‚°", "ê³µì¸ì¤‘ê°œì‚¬", "ì¤‘ê°œì‚¬ë¬´ì†Œ", "ë²•ë¬´ì‚¬", "ë“±ê¸°",
        "ê³„ì•½ì„œ", "ì”ê¸ˆ", "ì§‘ì£¼ì¸", "ë§¤ë„ì¸", "ë§¤ìˆ˜ì¸",
        "í‚¤ ë¶ˆì¶œ", "ë“±ê¸° ì´ì „", "ì†Œìœ ê¶Œ ì´ì „", "ì „ì…ì‹ ê³ "
    ]

    # ê³µì‹ ë„ë©”ì¸ íŒ¨í„´ (ì‹¤ì œ ì •ë¶€/ê³µê³µê¸°ê´€ ë„ë©”ì¸)
    OFFICIAL_DOMAINS = [
        ".go.kr",  # ëŒ€í•œë¯¼êµ­ ì •ë¶€ê¸°ê´€
        ".or.kr",  # ë¹„ì˜ë¦¬ ë‹¨ì²´
        ".ac.kr",  # ëŒ€í•™êµ
    ]

    # ê°€ì§œ URL íŒ¨í„´ (í”¼ì‹±ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë„ë©”ì¸ íŒ¨í„´)
    FAKE_URL_PATTERNS = [
        "-support.com", "-center.com", "-help.com", "-service.com",
        "-verify.com", "-security.com", "-update.com", "-login.com",
        "-bank.net", "-govt.net", "-official.net",
        "bit.ly", "tinyurl", "short"
    ]

    # ê¸´ê¸‰/ì••ë°• í‚¤ì›Œë“œ (í”¼ì‹±ì—ì„œ ìì£¼ ì‚¬ìš©)
    URGENCY_KEYWORDS = [
        "ì§€ê¸ˆ ë‹¹ì¥", "ì¦‰ì‹œ", "ê¸‰íˆ", "ë°”ë¡œ", "ë¹¨ë¦¬",
        "ì•ˆ í•˜ë©´", "í•˜ì§€ ì•Šìœ¼ë©´", "ë¶ˆì´ìµ", "ì†í•´",
        "ì‹œê°„ ë‚´", "ë§ˆê°", "ê¸°í•œ"
    ]

    # ê¸ˆì „ ìˆ˜ë ¹ í‚¤ì›Œë“œ (ì‚¬ìš©ìê°€ ëˆì„ ë°›ëŠ” ìƒí™© - ì •ìƒ)
    MONEY_RECEIVING_KEYWORDS = [
        "ì†¡ê¸ˆí•´ë“œë¦´ê²Œìš”", "ì†¡ê¸ˆí•´ ë“œë¦´ê²Œìš”", "ì†¡ê¸ˆ í•´ë“œë¦´ê²Œìš”",
        "ì…ê¸ˆí•´ë“œë¦´ê²Œìš”", "ì…ê¸ˆí•´ ë“œë¦´ê²Œìš”", "ì…ê¸ˆ í•´ë“œë¦´ê²Œìš”",
        "ì§€ê¸‰", "í™˜ê¸‰", "ë³´ìƒê¸ˆ", "ì§€ì›ê¸ˆ", "ë°°ìƒê¸ˆ"
    ]

    # ì‚¬ìš©ì í•­ì˜ í‚¤ì›Œë“œ (ì‚¬ìš©ìê°€ í˜‘ë°•/í•­ì˜í•˜ëŠ” ìƒí™© - ì •ìƒ)
    USER_COMPLAINT_KEYWORDS = [
        "í™˜ë¶ˆí•˜ì„¸ìš”", "í™˜ë¶ˆ í•´ì£¼ì„¸ìš”", "í™˜ë¶ˆí•´ ì£¼ì„¸ìš”",
        "ì‹ ê³ í•˜ê² ", "ê³ ì†Œí•˜ê² ", "ì†Œë¹„ìì›", "ê³µì •ìœ„",
        "í•­ì˜í•©ë‹ˆë‹¤", "í•­ì˜ë“œë¦½ë‹ˆë‹¤", "ì±…ì„ì§€ì„¸ìš”"
    ]

    def __init__(self):
        self.stats = {
            "total_filtered": 0,
            "downgraded": 0,
            "upgraded": 0,
            "passed": 0,
            "second_stage_checks": 0,
            "second_stage_downgrades": 0
        }
        # ê¸ˆì•¡ ì¶”ì¶œìš© ì •ê·œì‹
        import re
        self.amount_pattern = re.compile(r'([\d,]+)\s*ë§Œ\s*ì›')

        # 2ì°¨ LLM ê²€ì¦ìš© Gemini Client ì´ˆê¸°í™”
        if GEMINI_AVAILABLE:
            try:
                self.second_stage_llm = GeminiClient()
                logger.info("âœ“ 2nd stage LLM verification enabled (Gemini Flash)")
            except Exception as e:
                self.second_stage_llm = None
                logger.warning(f"Failed to initialize 2nd stage LLM: {e}")
        else:
            self.second_stage_llm = None

    def filter(
        self,
        text: str,
        llm_score: float,
        llm_reasoning: str = ""
    ) -> Dict:
        """
        LLM íŒì • ê²°ê³¼ë¥¼ Rule ê¸°ë°˜ìœ¼ë¡œ 2ì°¨ ê²€ì¦

        Args:
            text: í†µí™” ë‚´ìš©
            llm_score: LLMì´ íŒì •í•œ ì ìˆ˜ (0-100)
            llm_reasoning: LLMì˜ íŒì • ì´ìœ 

        Returns:
            {
                "final_score": ìµœì¢… ì ìˆ˜,
                "risk_level": ìœ„í—˜ë„,
                "reason": í•„í„° ì ìš© ì´ìœ ,
                "filter_applied": í•„í„° ì ìš© ì—¬ë¶€
            }
        """
        self.stats["total_filtered"] += 1

        # í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        text_lower = text.lower()
        reasoning_lower = llm_reasoning.lower()

        # í‚¤ì›Œë“œ ì¹´ìš´íŒ… ë° íƒì§€ëœ í‚¤ì›Œë“œ ëª©ë¡ ìˆ˜ì§‘
        detected_crime = [kw for kw in self.CRIME_KEYWORDS if kw in text_lower]
        detected_legit = [kw for kw in self.LEGIT_KEYWORDS if kw in text_lower]
        detected_urgency = [kw for kw in self.URGENCY_KEYWORDS if kw in text_lower]

        crime_count = len(detected_crime)
        legit_count = len(detected_legit)
        urgency_count = len(detected_urgency)

        # URL íŒ¨í„´ ì²´í¬
        has_fake_url = any(pattern in text_lower for pattern in self.FAKE_URL_PATTERNS)
        has_official_domain = any(domain in text_lower for domain in self.OFFICIAL_DOMAINS)

        # ì›ê²© ì œì–´ ê´€ë ¨ íŒì •ì¸ì§€ í™•ì¸ (í…ìŠ¤íŠ¸ + reasoning ëª¨ë‘ ì²´í¬)
        remote_keywords = ["ì›ê²©", "remote", "ì œì–´", "control", "ì•±", "ì„¤ì¹˜", "ì ‘ì†", "í™”ë©´"]
        is_remote_concern = any(
            keyword in text_lower for keyword in remote_keywords
        ) or any(
            keyword in reasoning_lower for keyword in remote_keywords
        )

        # === Rule 1: ì›ê²© ì œì–´ ì˜ì‹¬ + ì •ìƒ ì„œë¹„ìŠ¤ íŒ¨í„´ ===
        # LLMì´ 60-95ì  ì‚¬ì´ë¡œ íŒì • + ì›ê²© ì œì–´ ì–¸ê¸‰
        if 60 <= llm_score <= 95 and is_remote_concern:
            # ê°€ì§œ URLì´ ì—†ê³ , ë²”ì£„ í‚¤ì›Œë“œ ì ê³ , ì •ìƒ í‚¤ì›Œë“œ ìˆê³ , ê¸´ê¸‰ì„± ì—†ìœ¼ë©´ ì •ìƒ ì„œë¹„ìŠ¤ë¡œ ê²©í•˜
            if not has_fake_url and crime_count <= 1 and legit_count >= 1 and urgency_count == 0:
                self.stats["downgraded"] += 1
                # ê³µì‹ ë„ë©”ì¸ì´ ìˆìœ¼ë©´ ë” í™•ì‹¤í•œ ì‹ í˜¸
                if has_official_domain:
                    reason = "ê³µì‹ ë„ë©”ì¸(.go.kr ë“±)ì„ ì‚¬ìš©í•˜ëŠ” ì •ìƒ ì„œë¹„ìŠ¤ë¡œ íŒë‹¨ë¨"
                else:
                    reason = "ì›ê²© ì§€ì› ìš”ì²­ì´ì§€ë§Œ ì •ìƒ ì„œë¹„ìŠ¤ë¡œ íŒë‹¨ë¨ (ì˜ˆì•½ëœ ì¼ì •, ê³µì‹ ì±„ë„)"
                logger.info(
                    f"Rule Filter: ì •ìƒ ì„œë¹„ìŠ¤ë¡œ ê²©í•˜ "
                    f"(ë²”ì£„:{crime_count}, ì •ìƒ:{legit_count}, ê¸´ê¸‰:{urgency_count})"
                )
                return {
                    "final_score": 25,  # ì•ˆì „ êµ¬ê°„ìœ¼ë¡œ ê²©í•˜
                    "risk_level": "ë‚®ì€ ì£¼ì˜",
                    "reason": reason,
                    "filter_applied": True,
                    "original_score": llm_score,
                    "keyword_analysis": {
                        "crime": crime_count,
                        "legit": legit_count,
                        "urgency": urgency_count
                    },
                    "detected_techniques": detected_crime[:10]
                }

        # === Rule 2: ë‚®ì€ ì ìˆ˜ + ê³ ìœ„í—˜ í‚¤ì›Œë“œ ë§ìŒ ===
        # LLMì´ ë‚®ê²Œ íŒì •í–ˆì§€ë§Œ ë²”ì£„ í‚¤ì›Œë“œê°€ 5ê°œ ì´ìƒ
        if llm_score < 60 and crime_count >= 5:
            self.stats["upgraded"] += 1
            logger.warning(
                f"Rule Filter: ìœ„í—˜ë„ ìƒí–¥ "
                f"(ì›ì ìˆ˜:{llm_score}, ë²”ì£„í‚¤ì›Œë“œ:{crime_count})"
            )
            return {
                "final_score": 70,  # ê²½ê³  êµ¬ê°„ìœ¼ë¡œ ìƒí–¥
                "risk_level": "ì¤‘ìœ„í—˜",
                "reason": "LLM ì ìˆ˜ëŠ” ë‚®ì§€ë§Œ ë‹¤ìˆ˜ì˜ í”¼ì‹± í‚¤ì›Œë“œ ê°ì§€ë¨",
                "filter_applied": True,
                "detected_techniques": detected_crime[:10],
                "original_score": llm_score,
                "keyword_analysis": {
                    "crime": crime_count,
                    "legit": legit_count,
                    "urgency": urgency_count
                }
            }

        # === Rule 3: ê¸´ê¸‰ì„± + ê¸ˆìœµ ì¡°í•© (ì „í˜•ì  í”¼ì‹±) ===
        # ê¸´ê¸‰ì„± í‚¤ì›Œë“œ + ë²”ì£„ í‚¤ì›Œë“œê°€ ë§ìœ¼ë©´ ë†’ì€ ìœ„í—˜
        # ë‹¨, ì •ìƒ í‚¤ì›Œë“œê°€ ë§ìœ¼ë©´ (ë¶€ë™ì‚°, ë²•ë¥  ê±°ë˜ ë“±) ìƒí–¥í•˜ì§€ ì•ŠìŒ
        if urgency_count >= 2 and crime_count >= 3 and legit_count <= 2:
            if llm_score < 80:
                self.stats["upgraded"] += 1
                logger.warning(
                    f"Rule Filter: ê¸´ê¸‰ì„±+ê¸ˆìœµ íŒ¨í„´ ê°ì§€ "
                    f"(ê¸´ê¸‰:{urgency_count}, ë²”ì£„:{crime_count}, ì •ìƒ:{legit_count})"
                )
                return {
                    "final_score": 85,
                    "risk_level": "ê³ ìœ„í—˜",
                    "reason": "ê¸´ê¸‰ì„± ì••ë°• + ê¸ˆìœµ/ìˆ˜ì‚¬ í‚¤ì›Œë“œ ì¡°í•© (ì „í˜•ì  í”¼ì‹± íŒ¨í„´)",
                    "filter_applied": True,
                    "original_score": llm_score,
                    "keyword_analysis": {
                        "crime": crime_count,
                        "legit": legit_count,
                        "urgency": urgency_count
                    },
                    "detected_techniques": detected_crime[:10]
                }

        # === Rule 4: 2ì°¨ LLM ê²€ì¦ (ì• ë§¤í•œ ì¼€ì´ìŠ¤) ===
        # 60-95 ì ìˆ˜ëŒ€ + 2ì°¨ LLM ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ì¬ê²€ì¦
        if 60 <= llm_score <= 95 and self.second_stage_llm:
            second_check = self._second_stage_verification(text, llm_score, llm_reasoning)
            if second_check["is_safe"]:
                self.stats["downgraded"] += 1
                self.stats["second_stage_downgrades"] += 1
                logger.info(
                    f"Rule Filter: 2ì°¨ LLM ê²€ì¦ ì™„ë£Œ - ì •ìƒ íŒì • "
                    f"(ì›ì ìˆ˜:{llm_score}, 2ì°¨íŒì •:{second_check['reasoning']})"
                )
                return {
                    "final_score": 20,
                    "risk_level": "ì•ˆì „",
                    "reason": f"2ì°¨ LLM ê²€ì¦: {second_check['reasoning']}",
                    "filter_applied": True,
                    "original_score": llm_score,
                    "second_stage_result": second_check,
                    "keyword_analysis": {
                        "crime": crime_count,
                        "legit": legit_count,
                        "urgency": urgency_count
                    },
                    "detected_techniques": []
                }

        # === Rule í†µê³¼: ì›ë˜ LLM íŒì • ìœ ì§€ ===
        self.stats["passed"] += 1
        return {
            "final_score": llm_score,
            "risk_level": "original",
            "reason": "Rule filter passed - LLM íŒì • ìœ ì§€",
            "filter_applied": False,
            "original_score": llm_score,
            "keyword_analysis": {
                "crime": crime_count,
                "legit": legit_count,
                "urgency": urgency_count
            },
            "detected_techniques": detected_crime[:10]  # ìµœëŒ€ 10ê°œë§Œ ë°˜í™˜
        }

    def _second_stage_verification(
        self,
        text: str,
        first_score: float,
        first_reasoning: str
    ) -> Dict:
        """
        2ì°¨ LLM ê²€ì¦: ì• ë§¤í•œ ì¼€ì´ìŠ¤ë¥¼ ì¬ë¶„ì„

        Args:
            text: í†µí™” ë‚´ìš©
            first_score: 1ì°¨ LLM ì ìˆ˜
            first_reasoning: 1ì°¨ LLM íŒë‹¨ ì´ìœ 

        Returns:
            {
                "is_safe": bool,  # Trueë©´ ì •ìƒ, Falseë©´ ìœ„í—˜ ìœ ì§€
                "reasoning": str   # 2ì°¨ íŒì • ì´ìœ 
            }
        """
        self.stats["second_stage_checks"] += 1

        if not self.second_stage_llm:
            return {"is_safe": False, "reasoning": "2nd stage LLM not available"}

        # 2ì°¨ ê²€ì¦ìš© í”„ë¡¬í”„íŠ¸ (Chain-of-Thought + í•¨ì • íŒ¨í„´ íƒì§€)
        # ì£¼ì˜: analyze_phishing()ì´ ìë™ìœ¼ë¡œ "í†µí™” ë‚´ìš©: {text}" ì¶”ê°€í•˜ë¯€ë¡œ ì—¬ê¸°ì„  ì œì™¸
        verification_prompt = f"""ë‹¹ì‹ ì€ ë³´ì´ìŠ¤í”¼ì‹± 2ì°¨ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë°°ê²½**:
- 1ì°¨ AI íŒì •: {first_score}ì  (í”¼ì‹± ì˜ì‹¬)
- 1ì°¨ íŒì • ì´ìœ : {first_reasoning}

**ì¬ê²€ì¦ ì„ë¬´**: 3ë‹¨ê³„ ì²´ê³„ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

---

## ğŸ“‹ Step 1: ì˜ˆì™¸ ìƒí™© ë§¤ì¹­

ë‹¤ìŒ 3ê°€ì§€ **ì˜ˆì™¸ ìƒí™©** ì¤‘ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ì¸:

### âœ… ì˜ˆì™¸ 1: ì‚¬ìš©ìê°€ ëˆì„ ë°›ëŠ” ìƒí™©
**ì •ìƒ ì‹ í˜¸**:
- "ì†¡ê¸ˆí•´ë“œë¦´ê²Œìš”", "ì…ê¸ˆí•´ë“œë¦´", "ì§€ê¸‰", "í™˜ê¸‰", "ë³´ìƒê¸ˆ"
- ê°œì¸ì •ë³´(ì£¼ë¯¼ë²ˆí˜¸, ê³„ì¢Œ) ìš”êµ¬ â†’ ì„¸ê¸ˆ/ì†¡ê¸ˆ ì²˜ë¦¬ìš©ì´ë¯€ë¡œ ì •ìƒ
- **ì˜ˆì‹œ**: ë³´í—˜ê¸ˆ ì§€ê¸‰ + ì£¼ë¯¼ë²ˆí˜¸ ìš”êµ¬ (ì„¸ê¸ˆ ì²˜ë¦¬) âœ…

**âŒ í•¨ì • íŒ¨í„´ (í”¼ì‹±)**:
- "í™˜ë¶ˆ/í™˜ê¸‰" **+ ì•± ì„¤ì¹˜/ì›ê²©ì œì–´/URL ì ‘ì† ìš”êµ¬**
- **ì˜ˆì‹œ**: "ì¿ íŒ¡ í™˜ë¶ˆí•´ë“œë¦´ê²Œìš” + íŒ€ë·°ì–´ ì„¤ì¹˜" â†’ í”¼ì‹± âŒ
- **ì˜ˆì‹œ**: "ì‚¬ê¸° í”¼í•´ê¸ˆ ì°¾ì•˜ìŠµë‹ˆë‹¤ + cyber-police.me ì ‘ì†" â†’ í”¼ì‹± âŒ
- **ì´ìœ **: ì •ìƒ í™˜ê¸‰ì€ **ê³„ì¢Œë²ˆí˜¸ë§Œ** ìš”êµ¬, ì•±/URL/ì›ê²©ì œì–´ **ë¶ˆí•„ìš”**

### âœ… ì˜ˆì™¸ 2: ì‚¬ìš©ìê°€ í•­ì˜/í˜‘ë°•í•˜ëŠ” ìƒí™©
**ì •ìƒ ì‹ í˜¸**:
- "í™˜ë¶ˆí•´", "í™˜ë¶ˆí•˜ì„¸ìš”", "ì‹ ê³ í•˜ê² ", "ê³ ì†Œí•˜ê² ", "ì±…ì„ì ¸", "ì†Œë¹„ìì›"
- ì‚¬ìš©ìê°€ **í”¼í•´ìê°€ ì•„ë‹Œ í•­ì˜ì** ì—­í• 
- **ì˜ˆì‹œ**: "500% ìˆ˜ìµ ë‚œë‹¤ë©°! ë‹¹ì¥ í™˜ë¶ˆí•´ì¤˜" âœ…

### âœ… ì˜ˆì™¸ 3: ì†Œì•¡(10ë§Œì› ì´í•˜) ê¸´ê¸‰ ìš”ì²­
**ì •ìƒ ì‹ í˜¸**:
- "10ë§Œì›", "5ë§Œì›", "ì°¨ë¹„", "ê¸‰í•´" + ê°€ì¡±/ì§€ì¸
- ì†Œì•¡ ê¸‰ì „ì€ ì •ìƒ ê°€ëŠ¥ì„± ë†’ìŒ (ì¹œêµ¬ ê³„ì¢Œì—¬ë„ ì •ìƒ)
- **ì˜ˆì‹œ**: "ì—„ë§ˆ ì§€ê°‘ ìƒì–´ë²„ë ¸ì–´ 10ë§Œì›ë§Œ" âœ…

---

## ğŸ” Step 2: í•¨ì • íŒ¨í„´ ì²´í¬

ì˜ˆì™¸ 1ì— í•´ë‹¹í•˜ë”ë¼ë„ ë‹¤ìŒ **í”¼ì‹± ì‹ í˜¸**ê°€ ìˆìœ¼ë©´ í”¼ì‹±:
- âš ï¸ ì•± ì„¤ì¹˜ ìš”êµ¬ (íŒ€ë·°ì–´, ì›ê²©, APK, ë³´ì•ˆê´€ ë“±)
- âš ï¸ URL ì ‘ì† ìš”êµ¬ (.com, .net, bit.ly, ë‹¨ì¶• URL)
- âš ï¸ ì›ê²© ì œì–´ ìš”êµ¬ (ì ‘ì†ë²ˆí˜¸, í™”ë©´ ê³µìœ , ì œì–´ ê¶Œí•œ)
- âš ï¸ ê°€ì§œ ê³µê³µê¸°ê´€ ì‚¬ì¹­ (URLì´ .go.kr ì•„ë‹˜)

---

## âœ… Step 3: ìµœì¢… íŒë‹¨

**ë‹µë³€ í˜•ì‹ (JSON)**:
{{
  "step1_exception_match": "ì˜ˆì™¸ 1/2/3 ì¤‘ í•´ë‹¹í•˜ëŠ”ê°€? (ì˜ˆì™¸ë²ˆí˜¸ ë˜ëŠ” 'í•´ë‹¹ì—†ìŒ')",
  "step2_trap_detected": "í•¨ì • íŒ¨í„´ ë°œê²¬? (ì•±/URL/ì›ê²©ì œì–´ ìš”êµ¬ ì—¬ë¶€: yes/no)",
  "step3_final_decision": "ì •ìƒ ë˜ëŠ” í”¼ì‹±",
  "score": 0-100,
  "is_phishing": true ë˜ëŠ” false,
  "reasoning": "Step 1~3 ì¢…í•© íŒë‹¨ ê²°ê³¼ (2-3ë¬¸ì¥)"
}}

**í•µì‹¬ ë¡œì§**:
- ì˜ˆì™¸ í•´ë‹¹ âœ… + í•¨ì • ì—†ìŒ âœ… â†’ ì •ìƒ (score: 0-30, is_phishing: false)
- ì˜ˆì™¸ í•´ë‹¹ âœ… + í•¨ì • ìˆìŒ âŒ â†’ **í”¼ì‹±** (score: {first_score}, is_phishing: true)
- ì˜ˆì™¸ í•´ë‹¹ ì—†ìŒ âŒ â†’ í”¼ì‹± (score: {first_score}, is_phishing: true)"""

        try:
            # Gemini Flashë¡œ ë¹ ë¥´ê²Œ 2ì°¨ ê²€ì¦
            result = self.second_stage_llm.analyze_phishing(text, verification_prompt)

            # Gemini ì‘ë‹µ: {"score": int, "is_phishing": bool, "reasoning": str}
            is_phishing = result.get("is_phishing", True)  # ê¸°ë³¸ê°’: ìœ„í—˜
            second_score = result.get("score", first_score)
            reasoning_text = result.get("reasoning", "2ì°¨ ê²€ì¦ ì™„ë£Œ")

            # is_phishing: falseë©´ ì•ˆì „ (is_safe: true)
            is_safe = not is_phishing

            # ì¶”ê°€ ê²€ì¦: scoreê°€ ë‚®ìœ¼ë©´ (0-30) ì•ˆì „ìœ¼ë¡œ íŒë‹¨
            if second_score <= 30:
                is_safe = True

            return {
                "is_safe": is_safe,
                "reasoning": reasoning_text,
                "second_score": second_score
            }

        except Exception as e:
            logger.error(f"2nd stage verification failed: {e}")
            return {"is_safe": False, "reasoning": f"Error: {str(e)}"}

    def get_statistics(self) -> Dict:
        """í•„í„° í†µê³„ ë°˜í™˜"""
        return {
            **self.stats,
            "downgrade_rate": (
                self.stats["downgraded"] / self.stats["total_filtered"] * 100
                if self.stats["total_filtered"] > 0 else 0
            ),
            "upgrade_rate": (
                self.stats["upgraded"] / self.stats["total_filtered"] * 100
                if self.stats["total_filtered"] > 0 else 0
            )
        }

    def reset_statistics(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.stats = {
            "total_filtered": 0,
            "downgraded": 0,
            "upgraded": 0,
            "passed": 0,
            "second_stage_checks": 0,
            "second_stage_downgrades": 0
        }
